{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b08309-5824-4e18-b687-a78e024188bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.semseg_utils import *\n",
    "from src.data import *\n",
    "from models.SemSeg_Network import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor.detach().cpu().numpy().squeeze() \n",
    "    tensor_min, tensor_max = tensor.min(), tensor.max()\n",
    "    if tensor_max > tensor_min:\n",
    "        tensor = (tensor - tensor_min) / (tensor_max - tensor_min)\n",
    "    return (tensor * 255).astype(np.uint8)  \n",
    "\n",
    "data_path = '/root/home/MD/'\n",
    "\n",
    "test_images = data_pred(data_path, 'images_ASHEVILLE_S_3Band50cm')\n",
    "test_dataset = DataPrep(test_images, transform=transform)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# for i in range(1):\n",
    "i = 0\n",
    "model = Network(1)\n",
    "\n",
    "model_dict = torch.load('./pretrained_weights/DeepGlobe_SemSeg_SACloss.pth')\n",
    "\n",
    "modified_model_dict0 = {k.replace('module.', ''): v for k, v in model_dict.items()}\n",
    "modified_model_dict1 = {k.replace('segmentation.pcs_weight', 'segmentation.pcs_module.weight'): v for k, v in modified_model_dict0.items()}\n",
    "modified_model_dict = {k.replace('segmentation.pcs_bias', 'segmentation.pcs_module.bias'): v for k, v in modified_model_dict1.items()}\n",
    "\n",
    "\n",
    "model.load_state_dict(modified_model_dict)\n",
    "model.to('cpu')  # or 'cuda' if you're using GPU\n",
    "model.eval()\n",
    "batch_idx = 0\n",
    "\n",
    "for batch in test_loader:\n",
    "    inputs = batch\n",
    "    inputs = inputs.to('cpu')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred1 = model(inputs)\n",
    "\n",
    "    \n",
    "    input_image = tensor_to_image(inputs[0])\n",
    "    predicted_image = tensor_to_image(pred1[0])\n",
    "    input_image = input_image.transpose(1, 2, 0) \n",
    "\n",
    "    # cv2.imwrite(f\"/home/sara/Desktop/predictions/Road/SemSeg_ourLoss/models/SemSeg_CombinedLoss_ep{i}/predicted_cont0_{batch_idx}.png\", predicted_cont[0])\n",
    "    # cv2.imwrite(f\"/home/sara/Desktop/predictions/Road/SemSeg_ourLoss/models/SemSeg_CombinedLoss_ep{i}/predicted_image0_{batch_idx}.png\", predicted_image[0])\n",
    "    # cv2.imwrite(f\"/home/saraashojaeii/Desktop/Road Detection//predicted_{batch_idx}.png\", predicted_image[1])\n",
    "    \n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(input_image, cmap='gray')\n",
    "    ax[0].set_title('Input Image')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(predicted_image[1], cmap='gray')\n",
    "    ax[1].set_title('Predicted map 2')\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.semseg_utils import *\n",
    "from src.data import *\n",
    "from models.SemSeg_Network import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor.detach().cpu().numpy().squeeze() \n",
    "    tensor_min, tensor_max = tensor.min(), tensor.max()\n",
    "    if tensor_max > tensor_min:\n",
    "        tensor = (tensor - tensor_min) / (tensor_max - tensor_min)\n",
    "    return (tensor * 255).astype(np.uint8)  \n",
    "\n",
    "\n",
    "data_path = '/root/home/MD/'\n",
    "test_images, test_masks = data_pred(data_path, 'test', 'mass')\n",
    "\n",
    "test_dataset = DataPrep(test_images, test_masks, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "i = 0\n",
    "model = Network(1)\n",
    "\n",
    "model_dict = torch.load('./pretrained_weights/DeepGlobe_SemSeg_SACloss.pth')\n",
    "modified_model_dict0 = {k.replace('module.', ''): v for k, v in model_dict.items()}\n",
    "modified_model_dict1 = {k.replace('segmentation.pcs_weight', 'segmentation.pcs_module.weight'): v for k, v in modified_model_dict0.items()}\n",
    "modified_model_dict = {k.replace('segmentation.pcs_bias', 'segmentation.pcs_module.bias'): v for k, v in modified_model_dict1.items()}\n",
    "\n",
    "model.load_state_dict(modified_model_dict)\n",
    "model.to('cuda')  # or 'cuda' if you're using GPU\n",
    "model.eval()\n",
    "batch_idx = 0\n",
    "    \n",
    "test_count = 0\n",
    "total_test_miou = 0\n",
    "test_miou = 0    \n",
    "test_class_iou = 0\n",
    "total_test_class_iou = 0\n",
    "\n",
    "test_comm = 0\n",
    "test_corr = 0\n",
    "test_qual = 0\n",
    "total_test_comm = 0\n",
    "total_test_corr = 0\n",
    "total_test_qual = 0\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    test_x, test_y = batch\n",
    "    test_x, test_y = test_x.to('cuda'), test_y.to('cuda') \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mask, x = model(test_x)\n",
    "\n",
    "    x = x.detach()\n",
    "    mask = mask.detach()\n",
    "      \n",
    "    mask = torch.argmax(mask, dim=1).detach().cpu().numpy()  \n",
    "    test_y = test_y.squeeze().detach().cpu().numpy()  \n",
    "    mask = mask.squeeze(0)\n",
    "\n",
    "    comm, corr, qual = relaxed_f1(mask, test_y, 5)\n",
    "    tmiou, ciou = mIoU(mask, test_y, 2)\n",
    "\n",
    "    test_miou += tmiou\n",
    "    test_class_iou += ciou\n",
    "\n",
    "    test_comm += comm\n",
    "    test_corr += corr\n",
    "    test_qual += qual\n",
    "\n",
    "    total_test_comm += test_comm\n",
    "    total_test_corr += test_corr\n",
    "    total_test_qual += test_qual\n",
    "\n",
    "    total_test_miou += test_miou\n",
    "    test_miou = 0\n",
    "    test_comm = 0\n",
    "    test_corr = 0\n",
    "    test_qual = 0\n",
    "    test_count += 1\n",
    "\n",
    "\n",
    "total_test_class_iou = test_class_iou / test_count\n",
    "\n",
    "test_comm_avg = total_test_comm / test_count\n",
    "test_corr_avg = total_test_corr / test_count\n",
    "test_qual_avg = total_test_qual / test_count\n",
    "\n",
    "\n",
    "print(f\"test_comm_avg: {test_comm_avg}, test_corr_avg: {test_corr_avg}, test_qual_avg: {test_qual_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given values\n",
    "recall_12 = test_comm_avg / 100\n",
    "precision_12 = test_corr_avg / 100\n",
    "\n",
    "# Calculate F1 score for the new values\n",
    "f1_score_12 = 2 * (recall_12 * precision_12) / (recall_12 + precision_12)\n",
    "f1_score_12\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
